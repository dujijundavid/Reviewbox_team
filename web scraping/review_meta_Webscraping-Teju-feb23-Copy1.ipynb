{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import codecs\n",
    "import mysql.connector\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "folder = os.getcwd() + '\\\\reviewmeta_pages\\\\'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "# read the file we just stored\n",
    "source_product = pd.read_csv('source_product_test.csv', sep=',')\n",
    "\n",
    "problematic = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>amazon.ca</td>\n",
       "      <td>B00EAPCCW0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>amazon.ca</td>\n",
       "      <td>B000RIA95G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>amazon.uk</td>\n",
       "      <td>B0057H1HZI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>amazon.ca</td>\n",
       "      <td>B00CWR7HFK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>amazon.ca</td>\n",
       "      <td>B00QTCUV0C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Source     product\n",
       "0  amazon.ca  B00EAPCCW0\n",
       "1  amazon.ca  B000RIA95G\n",
       "2  amazon.uk  B0057H1HZI\n",
       "3  amazon.ca  B00CWR7HFK\n",
       "4  amazon.ca  B00QTCUV0C"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_product.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a link this script will fetch data from reviewmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checksource(url):\n",
    "    if (\".fr\" in url):\n",
    "        return \"amazon-fr\"\n",
    "    if (\".ca\" in url):\n",
    "        return \"amazon-ca\"\n",
    "    if (\".de\" in url):\n",
    "        return \"amazon-de\"\n",
    "    if (\".uk\" in url):\n",
    "        return \"amazon-uk\"\n",
    "    else:\n",
    "        return \"amazon\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### webscraping from reviewmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_per_product(cat,number_of_rev,soup,product):\n",
    "    output = {}\n",
    "    trust, rev_rate, rev_title, rev_det, rev_link_rm,rev_txt_am,rev_lnk_am = ([] for i in range(7))\n",
    "    \n",
    "    if(cat == \"good\"):\n",
    "        trust_soup = soup.find_all(\"div\",class_  = \"col-sm-2 col-xs-12 text-center review-pass-badge\")\n",
    "        if(len(trust_soup)<number_of_rev):\n",
    "            temp = soup.find_all(\"div\",class_ = \"col-sm-2 col-xs-12 text-center review-warn-badge\")\n",
    "            trust_soup = trust_soup + temp\n",
    "\n",
    "    elif(cat == \"bad\"):\n",
    "        trust_soup = soup.find_all(\"div\",class_  = \"col-sm-2 col-xs-12 text-center review-fail-badge\")\n",
    "        if(len(trust_soup)<number_of_rev):\n",
    "            temp = soup.find_all(\"div\",class_ = \"col-sm-2 col-xs-12 text-center review-warn-badge\")\n",
    "            trust_soup = trust_soup + temp\n",
    "\n",
    "    \n",
    "    for i in range(0,number_of_rev):\n",
    "        \n",
    "        trust.append      (int(re.findall(r'[0-9]+',str(trust_soup[i].text))[0])/100)                  #convert trust to 0 to 1 scale\n",
    "        rev_rate.append   (re.findall(r'[0-5]',str(soup.find_all(\"div\",class_  = \"col-md-1 col-xs-2 bw-rating\")[i].text))[0])\n",
    "        rev_title.append  (soup.find_all(\"div\",class_  = \"col-md-11 col-xs-10 show-title\")[i].text)\n",
    "        rev_det.append    (soup.find_all(\"div\",class_  = \"col-sm-10 col-xs-12\")[i].text)\n",
    "        rev_link_rm.append(soup.find_all(\"label\",class_= \"written-by\")[i].find(\"a\").get('href'))\n",
    "        rev_txt_am.append (soup.find_all('div',class_  = \"show-actual-review\") [i].text)\n",
    "        rev_lnk_am.append (soup.find_all('div',class_  = \"show-actual-review\") [i].find(\"a\").get('href'))\n",
    "\n",
    "    output[\"product\"]          = product\n",
    "    output[\"trust\"]            = trust   \n",
    "    output[\"review_rating\"]    = rev_rate\n",
    "    output[\"review_title\"]     = rev_title\n",
    "    output[\"reviewer_details\"] = rev_det\n",
    "    output[\"reviewer_link_RM\"] = rev_link_rm\n",
    "    output[\"rvwr_text_Amazon\"] = rev_txt_am\n",
    "    output[\"rvwr_link_Amazon\"] = rev_lnk_am \n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reviwer profile detials clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_details_dict(review_temp):\n",
    "    rev_dict = {\"Verified_Purchases\": 0, \"Nvr_verified_reviewer\"   : 0, \"Contains_rep_phrases\": 0,\n",
    "                  \"high_vol_day_rev\": 0, \"Critical_Rev_rating\"     : 0, \"Take_backs\"          : 0, \n",
    "                 \"Take_backs_rating\": 0, \"Overrep_part\"            : 0, \"Overrep_wrd_cnt\"     : 0,\n",
    "                 \"Easy_grade_rating\": 0, \"Overlapping_rev_history\" : 0, \"Brand_Rep_freq\"      : 0,\n",
    "                 \"Brand_rep_rating\" : 0, \"One_hit\"                 : 0 }\n",
    "\n",
    "    for rev_metric in review_temp:\n",
    "\n",
    "        if(\"Unverified Purchaser\" in rev_metric):\n",
    "            rev_dict[\"Verified_Purchases\"] = 0\n",
    "\n",
    "        if(\"Verified Purchaser\" in rev_metric):\n",
    "            rev_dict[\"Verified_Purchases\"] = 1\n",
    "\n",
    "    #Ex: Never-Verified Reviewer\n",
    "        if(\"Never-Verified Reviewer\" in rev_metric):\n",
    "            rev_dict[\"Nvr_verified_reviewer\"] = 1\n",
    "\n",
    "        if(\"Contains repetitive phrases\" in rev_metric):\n",
    "            rev_dict[\"Contains_rep_phrases\"] = 1\n",
    "\n",
    "        if(\"Created on a high volume day\" in rev_metric):\n",
    "            rev_dict[\"high_vol_day_rev\"] = 1\n",
    "\n",
    "        if(\"Critical Reviewer\" in rev_metric):\n",
    "            rev_dict[\"Critical_Rev_rating\"] = float(rev_metric[-4:-1])\n",
    "\n",
    "        if(\"Take-Back Reviewer\" in rev_metric):\n",
    "            rev_dict[\"Take_backs\"]         = int(re.findall(r'[0-9]+',rev_metric)[0])\n",
    "            rev_dict[\"Take_backs_rating\"]  = float(rev_metric[-4:-1])\n",
    "\n",
    "    #EX: Overrepresented Participation (posted 2 reviews)        \n",
    "        if(\"Overrepresented Participation\" in rev_metric):\n",
    "            rev_dict[\"Overrep_part\"]       = int(re.findall(r'[0-9]+',rev_metric)[0])   \n",
    "\n",
    "    #EX: Overrepresented word count (3 words)       \n",
    "        if(\"Overrepresented word count\" in rev_metric):\n",
    "            rev_dict[\"Overrep_wrd_cnt\"]    = int(re.findall(r'[0-9]+',rev_metric)[0])   \n",
    "\n",
    "    #Ex: Easy Grader (avg. rating: 4.8)        \n",
    "        if(\"Easy Grader\" in rev_metric):\n",
    "            rev_dict[\"Easy_grade_rating\"] = float(rev_metric[-4:-1])\n",
    "\n",
    "    #Ex: Overlapping Review History: reviewed 1 of 9 top products        \n",
    "        if(\"Overlapping Review History\" in rev_metric):\n",
    "            rev_dict[\"Overlapping_rev_history\"] = int(re.findall(r'[0-9]+',rev_metric)[0])/int(re.findall(r'[0-9]+',rev_metric)[1])\n",
    "\n",
    "    #Brand Repeater (2 of 53 reviews for this brand; avg rating: 5.0)\n",
    "        if(\"Brand Repeater\" in rev_metric):\n",
    "            rev_dict[\"Brand_Rep_freq\"]     = (re.findall(r'[0-9]+',rev_metric)[0])+\"/\"+(re.findall(r'[0-9]+',rev_metric)[1])\n",
    "            rev_dict[\"Brand_rep_rating\"]   = float(rev_metric[-4:-1])\n",
    "\n",
    "        if(\"One-Hit Wonder\" in rev_metric):\n",
    "             rev_dict[\"One_hit\"] = 1 \n",
    "    return rev_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### give review dataframe for a single prduct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_df_per_soup(soup, productname):\n",
    "    soup_good     = soup.find(\"div\", {\"id\": \"good-reviews\"})\n",
    "    no_of_good    = len(soup_good.find_all(\"div\",id = \"sample_reviews\"))  \n",
    "    soup_bad      = soup.find(\"div\", {\"id\": \"bad-reviews\"})\n",
    "    no_of_bad     = len(soup_bad.find_all(\"div\",id = \"sample_reviews\"))\n",
    "\n",
    "    good_reviews_sum = pd.DataFrame.from_dict(data_per_product(\"good\",no_of_good,soup_good,productname))\n",
    "    bad_reviews_sum  = pd.DataFrame.from_dict(data_per_product(\"bad\",no_of_bad,soup_bad,productname))\n",
    "\n",
    "    review_total              = good_reviews_sum.append(bad_reviews_sum).reset_index(drop=True)\n",
    "    review_total[\"Amazon_ID\"] = review_total[\"rvwr_link_Amazon\"].apply(lambda x: x[(x.rfind(\"/\"))+1:]) \n",
    "    \n",
    "   # print(review_total)\n",
    "    \n",
    "    # split individual review deets into attributes\n",
    "    all_review_dict=[]\n",
    "    for i in range(no_of_good + no_of_bad):\n",
    "        review_temp = review_total[\"reviewer_details\"][i].split(\"\\n\")\n",
    "        rev_details = rev_details_dict(review_temp)\n",
    "        all_review_dict.append(rev_details)\n",
    "\n",
    "    #merge all the dictonaries with same key\n",
    "    review_attributes = {}\n",
    "    for k in all_review_dict[0]:\n",
    "        review_attributes[k] = [d[k] for d in all_review_dict]\n",
    "\n",
    "    review_total= review_total.join(pd.DataFrame.from_dict(review_attributes))\n",
    "    return review_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading review meta pages with time lag on local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://reviewmeta.com/amazon-ca/B00EAPCCW0\n",
      "https://reviewmeta.com/amazon-ca/B000RIA95G\n",
      "https://reviewmeta.com/amazon-uk/B0057H1HZI\n",
      "https://reviewmeta.com/amazon-ca/B00CWR7HFK\n",
      "https://reviewmeta.com/amazon-ca/B00QTCUV0C\n",
      "https://reviewmeta.com/amazon-uk/B01ATS8NUQ\n",
      "https://reviewmeta.com/amazon-ca/B00063496C\n",
      "https://reviewmeta.com/amazon-fr/B005BOMTVS\n",
      "https://reviewmeta.com/amazon-uk/B000RXVJEQ\n",
      "https://reviewmeta.com/amazon-uk/B005BOMT72\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(source_product)):\n",
    "    time.sleep(1) #Hold 1 seconds before the next scrape.\n",
    "    num=str(i)\n",
    "  #  url = source_product[\"URL\"][i]\n",
    "    product = source_product[\"product\"][i]\n",
    "    source = checksource (source_product[\"Source\"][i])\n",
    "    path = os.getcwd() + '\\\\reviewmeta_pages\\\\'\n",
    "    filename = product +\"_\"+ source + '.htm'\n",
    "    review_meta_url = 'https://reviewmeta.com/'+ source +'/'+ product\n",
    "    print(review_meta_url)\n",
    "    response = requests.get(review_meta_url, headers = headers)\n",
    "    time.sleep(2)\n",
    "    with open(path + filename, 'w', encoding=\"utf8\") as file:\n",
    "        file.write(response.text)\n",
    "\n",
    "print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B00063496C_amazon-ca.htm\n",
      "B000RIA95G_amazon-ca.htm\n",
      "B000RXVJEQ_amazon-uk.htm\n",
      "B0057H1HZI_amazon-uk.htm\n",
      "B005BOMT72_amazon-uk.htm\n",
      "B005BOMTVS_amazon-fr.htm\n",
      "B00CWR7HFK_amazon-ca.htm\n",
      "B00EAPCCW0_amazon-ca.htm\n",
      "B00QTCUV0C_amazon-ca.htm\n",
      "B01ATS8NUQ_amazon-uk.htm\n"
     ]
    }
   ],
   "source": [
    "review_dataframe_mega = pd.DataFrame()\n",
    "files = os.listdir(path)\n",
    "for file_name in files:\n",
    "    print(file_name)\n",
    "    f = open(\"{}{}\".format(path,file_name),\"r\", encoding=\"utf-8\").read()  #creating the path \n",
    "    soup = BeautifulSoup(f)\n",
    "    if (soup.find_all(\"div\",id = \"sample_reviews\") != []):\n",
    "        review_dataframe_mega = pd.concat([review_dataframe_mega, get_review_df_per_soup(soup, file_name.split(\"_\")[-2])], ignore_index=True)\n",
    "    else:\n",
    "        problematic.append(file_name.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B005BOMT72', 'B00QTCUV0C']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dataframe_mega.to_csv(\"review_dataframe_mega.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trust</th>\n",
       "      <th>Verified_Purchases</th>\n",
       "      <th>Nvr_verified_reviewer</th>\n",
       "      <th>Contains_rep_phrases</th>\n",
       "      <th>high_vol_day_rev</th>\n",
       "      <th>Critical_Rev_rating</th>\n",
       "      <th>Take_backs</th>\n",
       "      <th>Take_backs_rating</th>\n",
       "      <th>Overrep_part</th>\n",
       "      <th>Overrep_wrd_cnt</th>\n",
       "      <th>Easy_grade_rating</th>\n",
       "      <th>Overlapping_rev_history</th>\n",
       "      <th>Brand_Rep_freq</th>\n",
       "      <th>Brand_rep_rating</th>\n",
       "      <th>One_hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.000000</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.557312</td>\n",
       "      <td>0.975806</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.252688</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>1.181720</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.962634</td>\n",
       "      <td>1.728495</td>\n",
       "      <td>2.588710</td>\n",
       "      <td>3.106452</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.465495</td>\n",
       "      <td>0.153857</td>\n",
       "      <td>0.115308</td>\n",
       "      <td>0.435139</td>\n",
       "      <td>0.382538</td>\n",
       "      <td>1.686506</td>\n",
       "      <td>2.012482</td>\n",
       "      <td>1.879490</td>\n",
       "      <td>4.014656</td>\n",
       "      <td>11.838545</td>\n",
       "      <td>2.341864</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trust  Verified_Purchases  Nvr_verified_reviewer  \\\n",
       "count  372.000000          372.000000             372.000000   \n",
       "mean     0.557312            0.975806               0.013441   \n",
       "std      0.465495            0.153857               0.115308   \n",
       "min      0.000000            0.000000               0.000000   \n",
       "25%      0.000000            1.000000               0.000000   \n",
       "50%      0.790000            1.000000               0.000000   \n",
       "75%      1.000000            1.000000               0.000000   \n",
       "max      1.000000            1.000000               1.000000   \n",
       "\n",
       "       Contains_rep_phrases  high_vol_day_rev  Critical_Rev_rating  \\\n",
       "count            372.000000        372.000000           372.000000   \n",
       "mean               0.252688          0.177419             1.181720   \n",
       "std                0.435139          0.382538             1.686506   \n",
       "min                0.000000          0.000000             0.000000   \n",
       "25%                0.000000          0.000000             0.000000   \n",
       "50%                0.000000          0.000000             0.000000   \n",
       "75%                1.000000          0.000000             3.125000   \n",
       "max                1.000000          1.000000             4.300000   \n",
       "\n",
       "       Take_backs  Take_backs_rating  Overrep_part  Overrep_wrd_cnt  \\\n",
       "count  372.000000         372.000000    372.000000       372.000000   \n",
       "mean     0.580645           0.962634      1.728495         2.588710   \n",
       "std      2.012482           1.879490      4.014656        11.838545   \n",
       "min      0.000000           0.000000      0.000000         0.000000   \n",
       "25%      0.000000           0.000000      0.000000         0.000000   \n",
       "50%      0.000000           0.000000      0.000000         0.000000   \n",
       "75%      0.000000           0.000000      1.000000         0.000000   \n",
       "max     26.000000           5.000000     32.000000        90.000000   \n",
       "\n",
       "       Easy_grade_rating  Overlapping_rev_history  Brand_Rep_freq  \\\n",
       "count         372.000000               372.000000           372.0   \n",
       "mean            3.106452                 0.017025             0.0   \n",
       "std             2.341864                 0.072571             0.0   \n",
       "min             0.000000                 0.000000             0.0   \n",
       "25%             0.000000                 0.000000             0.0   \n",
       "50%             4.700000                 0.000000             0.0   \n",
       "75%             5.000000                 0.000000             0.0   \n",
       "max             5.000000                 0.666667             0.0   \n",
       "\n",
       "       Brand_rep_rating     One_hit  \n",
       "count             372.0  372.000000  \n",
       "mean                0.0    0.255376  \n",
       "std                 0.0    0.436660  \n",
       "min                 0.0    0.000000  \n",
       "25%                 0.0    0.000000  \n",
       "50%                 0.0    0.000000  \n",
       "75%                 0.0    1.000000  \n",
       "max                 0.0    1.000000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_dataframe_mega.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for whatever reason the reveiw id is not unique lenght wise : pls see if this can be done nicer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apologies for the multiple ifs, pls see if these can be done more efficiently "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Make this a general function that takes product url as inout and give the review dataframe as output \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) scrape reviewer_link_RM and get that data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
