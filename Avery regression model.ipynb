{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation:\n",
    "\n",
    "\n",
    "###  Objective:\n",
    "Find variables that helps to explain product Salesrank in Amazon\n",
    "\n",
    "### What things this notebook has done?\n",
    "1. Change tabular data into item-wise dictionary\n",
    "\n",
    "2. Metrics generation:\n",
    "   1. Calculation: aggregation metrics (Average ratings)\n",
    "   2. Date: time metrics\n",
    "   3. Text: \n",
    "       average word count\n",
    "      \n",
    "\n",
    "3. Regression basedline model\n",
    "\n",
    "\n",
    "### What's the dataset is about?\n",
    "1. Avery's product reviews data from Amazon\n",
    "2. Sales Rank of Avery products under different categories\n",
    "\n",
    "\n",
    "### Run time\n",
    "\n",
    "\n",
    "### Common bugs:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are detailed code chunks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup working environment & Dataset\n",
    "* Load sales rank & review dataset for Avery product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug=True\n",
    "option=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "#!pip install quilt\n",
    "#!quilt install ResidentMario/missingno_data\n",
    "from quilt.data.ResidentMario import missingno_data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (2,3,8,11,12,24,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/David/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (28,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "ar1 = pd.read_csv('Avery_reviews.csv')\n",
    "asr1 = pd.read_csv('SalesRank_Avery.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options for modeling:\n",
    "* Group 1: more variability\n",
    "* Group 2: most reviews records\n",
    "\n",
    "Must under missing_value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if(option==1):\n",
    "    # more reviews and highly variant sales rank\n",
    "    common = ['B00006IBVB',\n",
    "     'B001HA2H58',\n",
    "     'B004HLZ1FM',\n",
    "     'B00V2M9O98',\n",
    "     'B0155U3EES',\n",
    "     'B01FKQBAES',\n",
    "     'B01HC4KIVW',\n",
    "     'B07DFY9YRH']\n",
    "elif(option==2):\n",
    "    # products with most reviews\n",
    "    common=['B00006IBVB', \n",
    "         'B0155U3EES', \n",
    "         'B001HA2H58', \n",
    "         'B00V2M9O98', \n",
    "         'B07DFY9YRH',\n",
    "        'B004HLZ1FM', \n",
    "         'B01HC4KIVW']\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if(debug):\n",
    "    asr=asr1[asr1['id'].isin(common)].set_index('id',drop=True)\n",
    "    #asr1 = asr1.set_index('id',drop = True)\n",
    "    ar=ar1[ar1['product'].isin(common)].set_index('product',drop=True)\n",
    "else:\n",
    "    asr = asr1.set_index('id',drop = True)\n",
    "    # Same as above, create another dictionary for review data\n",
    "    ar = ar1.set_index('product',drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform into key-value pairs by each unique product ID\n",
    "To make aggregation on review ratings, we need details on each product\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to store the information for each product. Each product represents one element of the dictionary.\n",
    "asr_dict = {}\n",
    "for i in asr.index.unique():\n",
    "    asr_dict[i] = asr.loc[i, ['source','date', 'category_id1',\n",
    "       'category_name1', 'category_rank1', 'category_id2', 'category_name2',\n",
    "       'category_rank2', 'category_id3', 'category_name3', 'category_rank3',\n",
    "       'category_id4', 'category_name4', 'category_rank4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B07DFY9YRH'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_list=list(asr_dict.keys())\n",
    "item_list[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Features Time based rank Features\n",
    "* log_rank \n",
    "* delta_rank\n",
    "* date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salesrank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in asr_dict:\n",
    "    if type(asr_dict[i]) != pd.core.series.Series:\n",
    "        asr_dict[i] = asr_dict[i].sort_values('date').reset_index()\n",
    "        asr_dict[i].drop_duplicates(inplace = True)\n",
    "        asr_dict[i]['date'] = pd.to_datetime(asr_dict[i]['date'])\n",
    "        asr_dict[i]['log_rank'] = asr_dict[i]['category_rank1'].map(lambda x: math.log(x))\n",
    "        asr_dict[i]['delta_rank'] = asr_dict[i]['log_rank'].diff()\n",
    "        a = asr_dict[i].index[0]\n",
    "        asr_dict[i].drop(a, inplace = True)\n",
    "        asr_dict[i]['date'] = asr_dict[i]['date'].dt.strftime('%Y-%m-%d')\n",
    "        asr_dict[i]['date'] = pd.to_datetime(asr_dict[i]['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in asr_dict:\n",
    "    if type(asr_dict[i]) != pd.core.series.Series:\n",
    "        asr_dict[i] = asr_dict[i].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_dict = {}\n",
    "for i in ar.index.unique():\n",
    "    ar_dict[i] = ar.loc[i, ['source','date','author', 'verified', 'vine', 'stars', 'pvotes', 'tvotes',\n",
    "       'title', 'text', 'image', 'video']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ar_dict:\n",
    "    if type(ar_dict[i]) != pd.core.series.Series:\n",
    "        ar_dict[i] = ar_dict[i].sort_values('date').reset_index()\n",
    "        ar_dict[i].drop_duplicates(inplace = True)\n",
    "        ar_dict[i]['date'] = pd.to_datetime(ar_dict[i]['date'])\n",
    "        ar_dict[i]['date'] = ar_dict[i]['date'].dt.strftime('%Y-%m-%d')\n",
    "        ar_dict[i]['date'] = pd.to_datetime(ar_dict[i]['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ar_dict:\n",
    "    if type(ar_dict[i]) != pd.core.series.Series:\n",
    "        ar_dict[i] = ar_dict[i].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Feature group: aggregated features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have created two dictionaries, next we are going to do the aggregation\n",
    "for i in asr_dict:\n",
    "    if i in ar_dict:\n",
    "        for j in asr_dict[i].index.unique():\n",
    "            if type(ar_dict[i]) != pd.core.series.Series:\n",
    "                asr_dict[i].loc[j, \"stars_recent_10\"] = ar_dict[i][ar_dict[i]['date'] <= asr_dict[i].loc[j, 'date']].tail(10)['stars'].mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in asr_dict:\n",
    "    if i in ar_dict:\n",
    "        for j in asr_dict[i].index.unique():\n",
    "            if type(ar_dict[i]) != pd.core.series.Series:\n",
    "                asr_dict[i].loc[j, 'stars_recent_oneweek'] = ar_dict[i][(ar_dict[i]['date'] <= asr_dict[i].loc[j, 'date']) & (ar_dict[i]['date'] >= (asr_dict[i].loc[j,'date'] - datetime.timedelta(days = 6)))]['stars'].mean()\n",
    "                \n",
    "                \n",
    "                asr_dict[i].loc[j, 'stars_recent_onemonth'] = ar_dict[i][(ar_dict[i]['date'] <= \n",
    "                                                                          asr_dict[i].loc[j, 'date']) & (ar_dict[i]['date'] >= (asr_dict[i].loc[j,'date'] - datetime.timedelta(days = 29)))]['stars'].mean()\n",
    "                \n",
    "                \n",
    "                asr_dict[i].loc[j, 'stars_avg'] = ar_dict[i][ar_dict[i]['date'] <= asr_dict[i].loc[j, 'date']]['stars'].mean()\n",
    "                \n",
    "                asr_dict[i].loc[j, 'review_acc'] = ar_dict[i][ar_dict[i]['date'] <= asr_dict[i].loc[j, 'date']]['date'].count()\n",
    "                \n",
    "                asr_dict[i].loc[j, 'reviewnum_oneweek'] = ar_dict[i][(ar_dict[i]['date'] <= \n",
    "                                                                          asr_dict[i].loc[j, 'date']) & (ar_dict[i]['date'] >= (asr_dict[i].loc[j,'date'] - datetime.timedelta(days = 6)))]['date'].count()\n",
    "                \n",
    "                \n",
    "                asr_dict[i].loc[j, 'reviewnum_onemonth'] = ar_dict[i][(ar_dict[i]['date'] <= \n",
    "                                                                          asr_dict[i].loc[j, 'date']) & (ar_dict[i]['date'] >= (asr_dict[i].loc[j,'date'] - datetime.timedelta(days = 29)))]['date'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Text related Features:\n",
    "* average word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# of words in the reviews\n",
    "# Generate a new column: average word count of review that happen on the same sales rank day\n",
    "# for i in df_review2.index.unique():\n",
    "#     df_review2.loc[i,'word_count'] = df_review2.loc[i,'text'].count(' ') + 1\n",
    "  \n",
    "for i in asr_dict:\n",
    "    try:\n",
    "        if i in ar_dict:\n",
    "            for j in asr_dict[i].index.unique():\n",
    "                if type(ar_dict[i]) != pd.core.series.Series:\n",
    "                    asr_dict[i].loc[j, 'avg_word_count'] = ar_dict[i][ar_dict[i]['date'] <= asr_dict[i].loc[j, 'date']]['text'].apply(lambda x: x.count(' ')+1).mean()\n",
    "                    asr_dict[i].loc[j, 'avg_word_count_10'] = ar_dict[i][ar_dict[i]['date'] <= asr_dict[i].loc[j, 'date']].tail(10)['text'].apply(lambda x: x.count(' ')+1).mean()        \n",
    "    except:\n",
    "        continue                                                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Features: reviewer status\n",
    "* all: count of varified_account reviews \n",
    "* past one week: count of varified_account reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for i in asr_dict:\n",
    "    if i in ar_dict:\n",
    "        for j in asr_dict[i].index.unique():\n",
    "            if type(ar_dict[i]) != pd.core.series.Series:\n",
    "                asr_dict[i].loc[j, 'verified_acc'] = (ar_dict[i][(ar_dict[i]['date'] <= asr_dict[i].loc[j, 'date']) & (ar_dict[i]['verified'] == True)]['date'].count()) / (ar_dict[i][ar_dict[i]['date'] <= asr_dict[i].loc[j, 'date']]['date'].count()) \n",
    "            if type(ar_dict[i]) != pd.core.series.Series:\n",
    "                asr_dict[i].loc[j, 'verified_acc_oneweek'] = (ar_dict[i][(ar_dict[i]['date'] <= \n",
    "                                                                          asr_dict[i].loc[j, 'date']) & (ar_dict[i]['date'] >= (asr_dict[i].loc[j,'date'] - datetime.timedelta(days = 6))) & (ar_dict[i]['verified'] == True)]['date'].count()) / (ar_dict[i][(ar_dict[i]['date'] <= \n",
    "                                                                          asr_dict[i].loc[j, 'date']) & (ar_dict[i]['date'] >= (asr_dict[i].loc[j,'date'] - datetime.timedelta(days = 6)))]['date'].count()) \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove problematic products with only 1 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_products=[]\n",
    "for i in asr_dict:\n",
    "    if type(asr_dict[i]['category_rank1'])!= pd.core.series.Series:\n",
    "        problem_products.append(i)\n",
    "problem_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in problem_products:\n",
    "    del asr_dict[item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Features: log rank & delta rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in asr_dict:\n",
    "    asr_dict[i]['log_salesrank'] = asr_dict[i]['category_rank1'].apply(lambda x: math.log(x))\n",
    "    asr_dict[i]['delta_salesrank'] = asr_dict[i]['log_salesrank'].diff()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we use the delta of log salesrank, the first row should be deleted\n",
    "for i in asr_dict:\n",
    "    asr_dict[i].drop(asr_dict[i].index[0],inplace = True)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can tell many products have missing value so the calculated fields are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Data preparation for modeling\n",
    "Models for different product groups\n",
    "    * Large salesrank variation\n",
    "    * Most reviews records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# To change the keys from product ids to numbers, preparing for the following loop.\n",
    "new_dict_asr=dict((i,asr_dict[k]) for i,k in enumerate(sorted(asr_dict.keys())))\n",
    "\n",
    "# pull out interested products to form a new dataframe\n",
    "\n",
    "a = new_dict_asr[0]\n",
    "for i in new_dict_asr:\n",
    "    new_dict_asr[i]=new_dict_asr[i].reset_index()\n",
    "    if new_dict_asr[i].loc[1,'id'] in common: \n",
    "        a = pd.concat([a,new_dict_asr[i]],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first product is what we don't want, (not in common), but in the above loop, it's more convenient to include that, so we delete it now.\n",
    "final_df = a[a['id'] != 'B00000JFNV']\n",
    "\n",
    "# put our interested columns in the final dataframe.\n",
    "final_df = final_df.reset_index(drop = True)[['id', 'date', 'category_name1',\n",
    "       'category_rank1','log_rank', 'delta_rank',\n",
    "       'stars_recent_10', 'stars_recent_oneweek',\n",
    "       'stars_recent_onemonth', 'stars_avg', 'review_acc', 'reviewnum_oneweek',\n",
    "       'reviewnum_onemonth', 'avg_word_count', 'verified_acc',\n",
    "       'verified_acc_oneweek', 'log_salesrank', 'delta_salesrank','avg_word_count_10']]\n",
    "\n",
    "\n",
    "# replace the NAs with 0\n",
    "final_df = final_df.fillna(0)\n",
    "temp=final_df\n",
    "#final_df.to_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling Part\n",
    "1. Check missing values for calculated fields\n",
    "2. Model construction\n",
    "3. Model results\n",
    "4. Interpretation of important variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 missing value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "complete_df= new_dict_asr[0]\n",
    "for i in new_dict_asr:\n",
    "    new_dict_asr[i]=new_dict_asr[i].reset_index()\n",
    "    complete_df= pd.concat([complete_df,new_dict_asr[i]],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg_word_count             0.0\n",
       "avg_word_count_10          0.0\n",
       "category_id1               0.0\n",
       "category_id2               0.0\n",
       "category_id3             100.0\n",
       "category_id4             100.0\n",
       "category_name1             0.0\n",
       "category_name2             0.0\n",
       "category_name3           100.0\n",
       "category_name4           100.0\n",
       "category_rank1             0.0\n",
       "category_rank2             0.0\n",
       "category_rank3           100.0\n",
       "category_rank4           100.0\n",
       "date                       0.0\n",
       "delta_rank                 0.0\n",
       "delta_salesrank            0.0\n",
       "id                         0.0\n",
       "index                      0.0\n",
       "level_0                   12.5\n",
       "log_rank                   0.0\n",
       "log_salesrank              0.0\n",
       "review_acc                 0.0\n",
       "reviewnum_onemonth         0.0\n",
       "reviewnum_oneweek          0.0\n",
       "source                     0.0\n",
       "stars_avg                  0.0\n",
       "stars_recent_10            0.0\n",
       "stars_recent_onemonth      0.0\n",
       "stars_recent_oneweek      19.7\n",
       "verified_acc               0.0\n",
       "verified_acc_oneweek      19.7\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of missing data points per column\n",
    "def missing_col(df):\n",
    "    missing_values_count = round(df.isnull().sum()/complete_df.shape[0]*100,1)\n",
    "    rm_list=missing_values_count[missing_values_count>35].index\n",
    "    return(missing_values_count,rm_list)\n",
    "\n",
    "missing_values_count1,rm_list1=missing_col(complete_df)\n",
    "missing_values_count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-27b09ab3842c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmissing_values_count2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrm_list2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmissing_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#complete_df=complete_df.drop(rm_list,axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmissing_values_count2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "missing_values_count2,rm_list2=missing_col(sub)\n",
    "#complete_df=complete_df.drop(rm_list,axis=1)\n",
    "missing_values_count2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = final_df[['stars_recent_10', 'stars_recent_oneweek', 'stars_recent_onemonth', 'stars_avg', 'review_acc', \n",
    "               'reviewnum_onemonth', 'avg_word_count', 'avg_word_count_10','verified_acc', 'verified_acc_oneweek']]\n",
    "\n",
    "y = final_df['log_rank']\n",
    "poly = PolynomialFeatures(interaction_only=True,include_bias = False)\n",
    "X = poly.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "prediction=reg.predict(X_test)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', reg.coef_)\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, prediction))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print('Coefficient of determination: %.2f'\n",
    "      % r2_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
